# -*- coding: utf-8 -*-
"""Text translation Stream lite web app

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18rnnBoBUuEnfgIWQY4BH-BUubo7eMhEy

## Installations
"""

!pip install ipykernel>=5.1.2
!pip install pydeck
!pip install streamlit==0.75.0
!pip install pyngrok
!pip install streamlit -q
!pip install streamlit --upgrade
!pip install streamlit-option-menu

"""### App"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile finalLHTranslation.py
# 
# import tensorflow as tf
# from tensorflow import keras
# import streamlit as st
# import pandas as pd
# import plotly.figure_factory as ff
# from streamlit_option_menu import option_menu
# from textblob import TextBlob 
# import tensorflow as tf
# # import tensorflow >= 1.10 and enable eager execution
# import matplotlib.pyplot as plt
# import matplotlib.ticker as ticker
# from sklearn.model_selection import train_test_split
# import unicodedata
# import re
# import numpy as np
# import os
# import time
#  
# 
# # let's do the navigation bar first
# 
# selected = option_menu(
#       menu_title= None, options=['Home','Features', 'About'], icons =['house','book','boxes'],menu_icon='cast', default_index=0, orientation = 'horizontal'
#   )
# 
# 
# 
# # setting containers
# header = st.container()
# translation = st.container()
# dataset = st.container()
# features = st.container()
# modelTraining = st.container()
# 
# # setting columns within the header container
# with header:
#   col1, col2 = st.columns([1,6])
# 
#   with col1:
#     st.image(
#     "https://cdn0.iconfinder.com/data/icons/joker-circus-by-joker2011-d3g8h6s/256/lion.png", width=100,)
# 
#   with col2:
#     st.markdown("<h1 style='text-align: left; color: Orange;'> Lion Heart Translation</h1>", unsafe_allow_html=True)
# 
#   def translate_unrolled(self,
#                         input_text, *,
#                         max_length=50,
#                         return_attention=True,
#                         temperature=1.0):
#     batch_size = tf.shape(input_text)[0]
#     input_tokens = self.input_text_processor(input_text)
#     enc_output, enc_state = self.encoder(input_tokens)
# 
#     dec_state = enc_state
#     new_tokens = tf.fill([batch_size, 1], self.start_token)
# 
#     result_tokens = []
#     attention = []
#     done = tf.zeros([batch_size, 1], dtype=tf.bool)
# 
#     for _ in range(max_length):
#       dec_input = DecoderInput(new_tokens=new_tokens,
#                               enc_output=enc_output,
#                               mask=(input_tokens!=0))
# 
#       dec_result, dec_state = self.decoder(dec_input, state=dec_state)
# 
#       attention.append(dec_result.attention_weights)
# 
#       new_tokens = self.sample(dec_result.logits, temperature)
# 
#     # If a sequence produces an `end_token`, set it `done`
#       done = done | (new_tokens == self.end_token)
#       # Once a sequence is done it only produces 0-padding.
#       new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)
# 
#       # Collect the generated tokens
#       result_tokens.append(new_tokens)
# 
#       if tf.executing_eagerly() and tf.reduce_all(done):
#         break
# 
#   # Convert the list of generates token ids to a list of strings.
#       result_tokens = tf.concat(result_tokens, axis=-1)
#       result_text = self.tokens_to_text(result_tokens)
# 
#       if return_attention:
#         attention_stack = tf.concat(attention, axis=1)
#         return {'text': result_text, 'attention': attention_stack}
#       else:
#         return {'text': result_text}
# 
# 
#   # Translator.translate = translate_unrolled
# 
#     # Add selectbox in streamlit
# 
# 
#   def main():
#     st.markdown("""<span style="word-wrap:break-word;">Lion Heart Translation is an App who's main porpose is to translate Kenyan local languages, that is Kalenjin, Luo, Kikuyu, etc. to English.</span>""", unsafe_allow_html=True)
#     option = st.selectbox(
#     'Which Local language would you like to translate from?',
#         ('none', 'Kikuyu', 'Kalenjin', 'Luo'))
#     st.write('You selected:', option)
#     text = st.text_area("Enter Text to translate here: ","lorem ipsum...",key = "<255>")
# 
#     if st.button("Translate"):
#       input_text = tf.constant(text)
#       reloaded = tf.saved_model.load('translator')
#       result = translate_unrolled(input_text)
#       
#       for tr in result['text']:
#         show = tr.numpy().decode()
#         st.success(show)
# 
# if __name__=='__main__':
#   main()
# 
# 
# if selected == 'About':
#   with dataset:
#     st.header('About')
#     st.markdown("""<span style="word-wrap:break-word;">The data used to build this model was obtained from a chapter in the Bible in each of the four languages.</span>""", unsafe_allow_html=True)
#     
#     # st.text('The data used to build this model was obtained from a chapter in the Bible in each of the four languages.')
#     st.text("here's what the Kalenjin looks side by side with it's English translation")
#     kaleme = pd.read_csv('/content/kaleme.csv', sep='delimiter', engine = 'python', header=None)
#     st.write(kaleme.head(5))
# 
# if selected == 'Features':
#   with features:
#     st.header('Features')
#     st.markdown('* **Hyperparameter tuning:** Here the user can tweak the model settings in pursuit of higher accuracy')
#     st.markdown('* **Language Dropdown:** Here the user can tweak the model settings in pursuit of higher accuracy')
#     st.markdown('* **Translation textbox:** Here the user can tweak the model settings in pursuit of higher accuracy')

! streamlit run finalLHTranslation.py & npx localtunnel --port 8501